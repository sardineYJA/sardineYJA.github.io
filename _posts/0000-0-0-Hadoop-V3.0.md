---
layout: post
title: "hadoop3.0 新特性"
date: 2019-10-19
description: "hadoop3.0新特性"
tag: Hadoop

---


# 新功能与特性

## 调整架构

基于jdk1.8（最低版本要求）

将Mapreduce 基于内存+io+磁盘，共同处理数据。

hdfs 通过最近block块计算，根据最近计算原则，本地block块，加入到内存，先计算，通过IO，共享内存计算区域，最后快速形成计算结果，比Spark快10倍。


## Erasure Encoding 纠删码

纠删码将数据存储空间节省50%hadoop-3.0之前，HDFS存储方式为每一份数据存储3份，这也使得存储利用率仅为1/3，3.0引入纠删码技术(EC技术)，实现1份数据+0.5份冗余校验数据存储方式。

EC是一种数据保护技术，最早用于通信行业中数据传输中的数据恢复,是一种编码容错技术，他通过在原始数据中加入新的校验数据，使得各个部分的数据产生关联性。
在一定范围的数据出错情况下,通过纠删码技术都可以进行恢复，EC技术可以防止数据丢失，又可以解决HDFS存储空间翻倍的问题。

创建文件时，将从最近的祖先目录继承EC策略，以确定其块如何存储。与3路复制相比，默认的EC策略可以节省50％的存储空间，同时还可以承受更多的存储故障。
建议EC存储用于冷数据，由于冷数据确实数量大，可以减少副本从而降低存储空间，另外冷数据稳定，一旦需要恢复数据，对业务不会有太大影响。


## 支持多个NameNode

允许允许多个备用NameNode，但Active的NameNode始终只有1个，余下的都是Standby。 
Standby NN会不断与JN（轻量级进程JournalNode）同步，保证自己获取最新的editlog，并将edits同步到自己维护的image中去，实现热备。
在发生failover的时候，立马切换成active状态，对外提供服务。同时，JN只允许一个active状态的NN写入。


## Disk Balancer

Disk Balancer 支持单个Datanode上，不同硬盘间的数据balancer。
老版本的hadoop只支持在Datanode之间进行balancer，每个节点内部不同硬盘之间若发生了数据不平衡，则没有一个好的办法进行处理。
现在可以通过hdfs diskbalancer命令，进行节点内部硬盘间的数据平衡。
该功能默认是关闭的，需要手动设置参数dfs.disk.balancer.enabled为true来开启。


## 默认端口修改

- Namenode ports: 50470 --> 9871, 50070--> 9870, 8020 --> 9820

- Secondary NN ports: 50091 --> 9869,50090 --> 9868

- Datanode ports: 50020 --> 9867, 50010--> 9866, 50475 --> 9865, 50075 --> 9864


## MapReduce提升

Tasknative优化：为MapReduce增加了C/C++的map output collector实现（包括Spill，Sort和IFile等），通过作业级别参数调整就可切换到该实现上。对于shuffle密集型应用，其性能可提高约30%。

MapReduce内存参数自动推断。在Hadoop 2.0中，为MapReduce作业设置内存参数非常繁琐，涉及到两个参数：mapreduce.{map,reduce}.memory.mb和mapreduce.{map,reduce}.java.opts，一旦设置不合理，则会使得内存资源浪费严重，比如将前者设置为4096MB，但后者却是“-Xmx2g”，则剩余2g实际上无法让java heap使用到。


# reference

https://www.jianshu.com/p/a2c2fe4371ea

https://www.cnblogs.com/yujianming/p/8309045.html


