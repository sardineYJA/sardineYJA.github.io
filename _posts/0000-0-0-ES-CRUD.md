---
layout: post
title: "ES CURD 操作"
date: 2019-07-08
description: "Elasticsearch"
tag: Elasticsearch

---


## CURD 操作

curl测试：`curl -X<VERB> '<PROTOCOL>://<HOST>:<PORT>/<PATH>?<QUERY_STRING>' -d '<BODY>'`

- VERB : GET, POST, PUT, HEAD, DELETE
- PROTOCOL : http 或 https
- HOST : 集群中任意节点的主机名
- PORT : 运行ES HTTP服务的端口
- PATH : 终端路径
- QUERY_STRING : 任意可选的查询字符串参数，例如：?pretty 将格式化地输出JSON返回值
- BODY : 格式的请求体


## 差异

```sh
# 如果文档1存在，则两个都是更新，不存在则都创建
PUT /test_index/doc/1
POST /test_index/doc/1
{
  "name": "yang"
}

# 如歌文档1不存在，PUT 不可创建，POST可以创建
PUT /test_index/doc/
POST /test_index/doc/
{
  "name": "yang"
}
```

PUT是幂等方法，POST不是。
PUT用于更新，POST用于新增比较合适。
所谓幂等是指不管进行多少次操作，结果都一样。

## Kibana 样例

```sh
# 浏览器直接查询
http://172.16.7.124:9200/_cat/indices?v   # 查看每个索引详细信息

.../_cat/health?v
.../_cat/nodes?v      # 各个节点

.../索引名
.../索引名/_search    # 默认只显示10条
.../索引名/_count
```

```sh
GET /_count?pretty      # 个数
{
	"query": {
		"match_all":{}
	}
}
```

```sh
GET _cat/segments/索引名?v  # 某个索引的Segment memory
GET _cat/nodes?v            # 节点
GET _cat/indices?v          # 每个索引详细信息
GET 索引名/_settings         # 某个索引的设置
GET _cat/shards/索引名?v     # 某个索引分片信息 
```

## 新增

db为_index，user为_type, 1为_id（没有指定id,将是随机字符串）
```sh
POST /db/user/1
{
	"name":"yang",
	"password":"123",
	"age":"25"
}


GET /db/user/1      # 查询
DELETE /db/user/1   # 删除
```

## 查询

查找：`url/<index>/<type>/_search`

index, type 可选择

- took 表示耗时(毫秒）
- hits 表示命中记录
- timed_out 表示是否超时
- score 表示匹配的程序，默认是按照这个字段降序排列

```sh

GET _search    # 查找所有

GET _search    # 查询含有Hello
{
  "query": {
    "query_string": {
      "query": "Hello"
    }
  }
}

GET _search   # 查询字段title含有Hello的（fields默认_all）
{
  "query": {
    "query_string": {
      "query": "Hello",     # 查询含有Hello
      "fields": ["title"]
    }
  }
}

GET _search   # 查询字段year是1995的
{
	"query": {
		"term": {           # term查询，对输入不做分词
			"year": 1995      # 将字符设置为 keyword（不分词）
		}
	}
}


# 查找movices索引movie类型里文档title字段包含“Now”的数据。
GET movies/movie/_search 
{
  "explain": true,     # 查看计算相关性过程
  "query":{
    "match":{
      "title":"Now"
    }
  }
}


GET /_search        # 常数分数查询
{
  "_source": ["id", "name"],   # 查询的字段
  "from": 10,                  # 深度分页，可换scroll
  "size": 5,                   # 指定条数

  "query": {
    "constant_score": {
      "filter": {       # constant_score 中 query 转成 filter  
                        # 忽略TF-IDF计算，避免相关性算分的开销
        "term": {   # term查询，对输入不做分词，查询结构化数据
          "year": 1994
        }
      }
    }
  },

  "sort": [
    {"date": {"order": "desc"}},      # 时间字段降序
    {"_sorce": {"order": "asc"}}      # 算分字段升序
  ]
}


```


## bool 查询

- must : 必须匹配，贡献算分
- should : 选择性匹配，贡献算分
- must_not : Filter Context 查询字句，必须不匹配
- filter : Filter Context 必须匹配，但不贡献算分 


```sh
POST /products/_search
{
  "query": {
    "bool": {
      "must": {
        "term": {"price": "30"}
      },
      "filter": {
        "term": {"isNew": "true"}
      },
      "must_not": {
        "range": {
          "price": {"lte": 10} # range范围查询，小于等于10
        }
      },
      "should": [
        {"term": {"productID.keyword": "IUS-234-ESC"}},
        {"term": {"productID.keyword": "IJN-923-UWI"}}
      ]
    }
  }
}
```



# 删除

```sh
DELETE /blog/article/1  # 根据id删除一条记录
DELETE /blog/article    # 删除 type
DELETE /blog            # 删除 index
```

```sh
DELETE _all   # 删除所有，注意
```
为了避免大量删除，elasticsearch.yml 中修改
`action.destructive_requires_name: true`。
设置之后只限于使用特定名称来删除索引，使用_all 或者通配符来删除索引无效。


## 查找匹配后删除

```sh
POST /blog/article/_delete_by_query
{
  "query": {
    "match": {
      "content":"Hello"  # 删除content字段中有Hell的记录
    }
  }
}
```

# 聚合

```sh
POST employees/_search
{
  "size": 0,   # 只需要返回聚合结果
  "aggs": {
    "max_salary": {                  # 聚合名
      "max": {"field": "salary"}     # 聚合字段
    },
    "min_salary": {
      "min": {"field": "salary"}
    },
    "avg_salary": {
      "avg": {"field": "salary"}
    }
  }
}
```

```sh
POST employees/_search
{
  "size": 0,   # 只需要返回聚合结果
  "aggs": {
    "jobs": {                          # 聚合名，terms分桶
      "terms":{"field": "job.keyword"} # 统计每种工作的数量
    }
  }
}
```

分片会导致某些聚合不准确，查看：
- sum_other_doc_count：表示这次聚合中没有统计到的文档数。
- doc_count_error_upper_bound：表示没有在这次聚合中返回、但是可能存在的潜在聚合结果。

优化：
- 不分片，所有数据在一个shard上。
- 在聚合中使用route，将需要聚合的数据路由到同一个节点上。



# 分词器

- standard   （默认）将词汇单元转换成小写形式，并去除停用词和标点符号。中文采用的方法为单字切分。
- whitespace  空格分隔符，仅仅是去除空格，对字符没有lowcase化,不支持中文。
- stop        删除stop words，增加了去除英文中的如the，a等，也可加要设置常用单词，不支持中文。
- keyword     不分词
- ik_max_word 中文分词，最细颗粒
- ik_smart    中文分词，最粗颗粒

## 测试

```sh
GET _mapping    # 查看
```

```sh
GET <index>/<type>/_analyze    # 测试分词器效果，index和type可选
{
  "analyzer": "standard",
  "text": "this is a test 这是中文，中华人民共和国"
}
```

```sh
GET _search
{
  "query": {
    "query_string": {
        "query": "Hello",
        "analyzer": "standard"     # 查询时指定分词器
    }
  }
}
```

创建 index mapping 时指定 search_analyzer

```sh
PUT /book
{
  "mappings": {
    "doc": {
      "properties": {
        "title": {
          "type": "text",
          "analyzer": "whitespace",       # 分词器
          "search_analyzer": "standard"   # 查询分词器
        }
      }
    }
  }
}
```

- 不指定分词时，会使用默认的standard。

- 明确字段是否需要分词，不需要分词的字段将type设置为keyword，可以节省空间和提高写性能。


## 自定义分词

```sh
PUT /custom_analyzer
{
  "settings": {
    "analysis": {
      "analyzer": {
        "my_analyzer": {
          "type": "custom",
          "tokenizer": "standard",
          "char_filter": ["html_strip"], # 去html标签和转换html实体
          "filter": ["lowercase"]        # 将字母转化成小写
        }
      }
    }
  }
}
# 测试
POST /custom_analyzer/_analyze
{
  "analyzer": "my_analyzer",
  "text": ["This is 中华人民共和国", "<p>I&apos;m so <b>happy</b>!</p>"]
}
```



# 配置跨集群搜索

早期版本使用Tribe Node。ES5.3后，引入Cross Cluster Search功能。

模拟启动3个集群：
```sh
bin/elasticsearch -E node.name=cluster0node -E cluster.name=cluster0 -E path.data=cluster0_data -E discovery.type=single-node -E http.port=9200 -E transport.port=9300
bin/elasticsearch -E node.name=cluster1node -E cluster.name=cluster1 -E path.data=cluster1_data -E discovery.type=single-node -E http.port=9201 -E transport.port=9301
bin/elasticsearch -E node.name=cluster2node -E cluster.name=cluster2 -E path.data=cluster2_data -E discovery.type=single-node -E http.port=9202 -E transport.port=9302
```

在每个集群上设置：
```sh
PUT _cluster/settings
{
  "persistent": {
    "cluster": {
      "remote": {
        "cluster0": {
          "seeds": ["127.0.0.1:9300"]
        },
        "cluster1": {
          "seeds": ["127.0.0.1:9301"]
        },
        "cluster2": {
          "seeds": ["127.0.0.1:9302"]
        }
      }
    }
  }
}
```

查询：
```sh
GET /users,cluster1:users,cluster2:users/_search
```



# reference

https://www.cnblogs.com/zhuzi91/p/8228214.html

https://cloud.tencent.com/developer/article/1391008

https://www.cnblogs.com/xiaobaozi-95/p/9328948.html

