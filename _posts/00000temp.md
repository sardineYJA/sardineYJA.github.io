


## 索引

1 天 10 亿 300 G

索引大小，多少合理

分片数量，大小，对应占内存大小，多少合理

索引按大小，日期切分不同应用场景

script 写，如何变量自增 1 




## 版本差异



## 滚动升级

5.x     升级到 5.y 滚动升级
5.6     升级到 6.x 滚动升级
5.0-5.5 升级到 6.x 需要全节点关闭升级
6.x     升级到 6.y 滚动升级


1. 关闭分片
```sh
PUT _cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "none"
  }
}

POST _flush/synced
```

2. 升级单个 ES 节点

3. 升级节点上的插件

4. 重启节点会恢复分片，等待恢复
```sh
PUT _cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "all"
  }
}

GET _cat/recovery
```

注意：在滚动升级期间，不能将新版本节点上主分片的副本分配给具有旧版本节点，因为旧版本可能无法理解新版本数据格式。这时候（只有一个升级的节点）副本将保持未分配状态，并且状态保持 yellow 。当没有分片在 initializing 或 relocating，则继续升级另一个，副本就可得到分配，从而恢复 green。

5. 重复以上步骤

注意：滚动升级期间，任何新功能都不允许使用（此期间属于向后兼任模式）。当完成所有升级后，新功能便可使用，但是之后就无法恢复向后兼容模式，即不可再将低版本的节点加入到集群中。如果在升级过程中出现网络故障（将所有剩余的旧节点与群集隔离开）的极少数情况，则必须对旧节点脱机并进行升级后，才能够加入群集。


## docker 滚动升级



## searchguard 





## docker 




## ES id 长度

最长：512 bytes （170个中文，510 字节）







## 条件删除

```sh
POST index_name/_delete_by_query
{
  "query": {
    "term": {
      "project": {
        "value": "1"
      }
    }
  }
}

# 默认情况下，_delete_by_query自上而下批量1000条数据，可在URL中使用参数scroll_size
# _delete_by_query?scroll_size=5000
```











## 数据迁移
```sh
POST _reindex
{
  "conflicts": "proceed",
  "source": {
    "remote": {
      "host": "http://10.82.195.128:9200",
      "username": "elkproxy",
      "password": "Jdfs8dE",
      "socket_timeout": "20m",
      "connect_timeout": "20m"
    },
    "index": "dylog_p2m1_gamelog-2020.09.04-000002",
    "size": 8000
  },
  "dest": {
    "index": "dylog_p2m1_gamelog-2020.09.04-000002",
    "op_type": "create",
    "type": "doc"
  }
}


GET _tasks?pretty&detailed=true&actions=*reindex
POST _tasks/7EgqykHmRKuMhsDQmmktSQ:15828/_cancel  
GET _cat/indices?v&index=*p2m1*
```

1. 注意开启 10.82.195.128 9200 的防火墙
2. 6.0的版本不允许一个 index 下面有多个 type
3. 在 dest 目标索引的集群 kibana 执行，但是此 kibana 连接的 ES 节点需要对 source 里面的远程地址开放白名单。`reindex.remote.whitelist: "XXX.XXX.XXX.XXX:9200"`



## 统计游戏日志
```sh
GET sw*/_search
{
  "size": 0,
  "query": {
    "range": {
      "@timestamp": {
        "gte": "2020-10-17",
        "lt": "2020-10-18"
      }
    }
  },
  "aggs": {
    "all_host": {
      "terms": {
        "field": "fields.host",
        
        "size": 1000
      }
    },
    "stats_all_bucket": {
      "stats_bucket": {
        "buckets_path": "all_host>_count"
      }
    }
  }
}
```



## @timestamp 时间戳

```sh
# 这里查询的是 11-01 到 11-03 整三天的数据
GET test-*/_search
{
  "query": {
    "range": {
      "@timestamp": {
        "gte": "2020-10-31T16:00:00.000Z", 
        "lt": "2020-11-03T15:59:59.000Z"
      }
    }
  }
}

# 如果转成时间戳进行查询，是对 11-01 进行时间戳转换而不是 10-03 16点
# 2020-11-01 00:00:00:000 ==> 1604160000000

GET test-*/_search
{
  "query": {
    "range": {
      "@timestamp": {
        "gte": 1604160000000,
        "lte": 1604419199999,
        "format": "epoch_millis"
      }
    }
  }
}
```


## fielddata 属性

Fielddata 针对 text 字段在默认时是禁用的。当对 text 设为 true 时，该字段可用于`聚合``排序`或在`脚本`中。

Fielddata 会占用大量堆空间，尤其是在加载大量的文本字段时，所以 text 不推荐使用。

例如：查询某个 text 字段的值为 "" 

方法1: "fielddata": true

```sh
PUT test-yang
{
  "mappings": {
    "doc": {
      "properties": {
        "name": {
          "type": "text",
          "fielddata": true            # 需要使用脚本
        }
      }
    }
  }
}

GET test-yang/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "exists": {
            "field": "name"                       # 必须存在 name 字段的
          }
        },
        {
          "script": {
            "script": "doc['name'].length == 0"    # 查询 name="" 或没有 name 字段或 name: null
            # 这里的 length 指值的个数，不是字符串长度，如 name: ["123", ""] 此时 length 为 2
            # 不使用 fielddata, name.keyword 发现并不能实现查询某个 text 字段的值为 ""
          }
        }
      ]
    }
  }
}
```

方法2：wildcard

这样会匹配没有任何字符的 message，例如："" 或 "   " 或 "\n\n"。只有空格和换行符都会被筛选出来。

```sh
GET test-yang/_search
{
  "query": {
    "bool": {
      "must": [
        {
          "exists": {
            "field": "message"
          }
        }
      ],
      "must_not": [
        {
          "wildcard": {
            "message": {
              "value": "*"
            }
          }
        }
      ]
    }
  }
}
```

## 高亮 HTML 元素被切割

number_of_fragments =0 时指定字段整个内容被高亮标记，而不是分词后的某个词被高亮。

```sh
"highlight": {
    "pre_tags": "@elk-highlight-begin@",
    "post_tags": "@elk-highlight-end@",
    "fields": {
        "*": {
            "number_of_fragments": 0       
        }
    }
}
```

## logstash input 字符乱码

codec => plain { charset=>"UTF-8"} 指定

```sh
input {
  file {  # 也可是其他 http 等插件
    path=>["/home/test.txt"]
    codec => plain { charset=>"UTF-8"}
  }
}
```


















# jdk

openjdk 只包含最精简的JDK: `java -version`

```sh
yum install java-1.8.0-openjdk  
yum install java-1.8.0-openjdk-devel  # 补充 jstack jmap 等命令
```

```sh
#!/bin/bash 

pid=$1
cpu_use=$2

if [ $# -lt 1 ]; then 
  echo "USAGE: $0 pid [cpu_use]"
  echo "e.q.: $0 23979"
  exit 1;
fi

if test -z "$cpu_use"; then 
  cpu_use=20
fi

grep_jstack()
{
  is_start="false"
  while read line 
  do 
    if echo "nid=0x"${line} | grep -q $1; then 
      is_start="true"
    elif [[ "$is_start" = "true" ]] && [ -z "${line}" ]; then 
      break;
    fi
  done < /tmp/s-$pid
}

grep_all()
{
  while read line
  do
    if [ -n "${line}" ]; then
      grep_jstack ${line}
      echo "---------------------------------------"
    fi
  done < /tmp/j-$pid
}

jstack $pid > /tmp/s-$pid &
jstack_pid=$!

top -H -b -n 1 -p $pid | sed -n '8,$p' | awk -v val=$cpu_use '$9>val{printf("%x\n", $1);fflush()}' > /tmp/j-$pid

wait $jstack_pid

grep_all

echo "--------------------- End --------------------\n\n"
```









