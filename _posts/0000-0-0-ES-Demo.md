---
layout: post
title: "ES 常用操作"
date: 2020-05-31
description: "Elasticsearch"
tag: ELK

---


## 换GC

```sh
-XX:+UseG1GC
-XX:MaxGCPauseMillis=300
```

## 修改索引，副本数量，refresh时间

```sh
# 数据量不大就无须此步骤
PUT index_name/_settings
{
    "refresh_interval": "5s",  
    "number_of_shards": 2,        # 分片数不能动态修改
    "number_of_replicas": 1

}
```

## 部分主分片未分配，集群显示red

```sh
GET _cluster/allocation/explain    # 查看主分片未分配原因 

GET _cat/indices?v                 # 查看哪些索引red
# 不重要索引，可直接close
```

## 查看各个分片分别在哪些节点上

```sh
GET _cat/shards?v

GET /_cat/allocation?v   # 查看每个节点的磁盘占用

GET /_cat/fielddata?v&s=size:desc    # 可以查看字段占用的堆内存
```


## 合并segment

```sh
GET _cat/segments/索引名?v
POST 索引名/_forcemerge?max_num_segments=1  # 合并成一个（根据具体情况）
GET _task?actions=*merge?detailed=true      

GET _cat/nodes?v    # ES节点上segment占用的内存
```


## 修改索引字段数量

```sh
PUT index_name/_settings
{
  "index.mapping.total_fields.limit": 3000  # 默认最多字段数1000
}
```


## 关闭索引

```sh
POST 索引名/_close
POST 索引名/_open
# 索引关闭，开销基本0，但无法进行读写
```


## 删除.del文件

```sh
# es在检索过程中也会把.del文件进行检索过滤，如有大量的.del文件，应该让.del真正的从es中抹去，优化检索的效率。
# 在索引合并阶段就会删除.del文件
curl -X POST "http://node01:9200/索引名/_forcemerge?only_expunge_deletes=true"
```


## 查询特殊符号命名的index

转义字符用：%
例如：
```sh
# GET /<logstash-{now/d}>/_search
GET /%3Clogstash-%7Bnow%2Fd%7D%3E/_search
```


## 修改searchguard副本数

```sh
PUT searchguard/_settings
{
  "index": {
    "auto_expand_replicas": "0-3"
  }
}
```

## 防止脑裂导致版本差异

```sh
PUT _cluster/settings
{
  "transient": {
    "discovery": {
      "zen": {         # 一般3个master即可
        "minimun_master_nodes": "2"
      }
    }
  }
}
```

## 文档刷新时间

```sh
PUT */_settings
{
  "refresh_interval": -1
}
```


## Kibana 查询中文索引

链接中的中文需要URL编码，而DSL里面直接中文即可

```sh
PUT /%3Cdylog-%e6%b5%8b%e8%af%95-%7Bnow%2Fd%7D-000001%3E
{
  "aliases": {
    "dylog-测试_write": {}
  }
}
``` 



## 将节点所有分片移走

```sh
PUT _cluster/settings
{
  "transient": {
    "cluster": {
      "routing": {
        "allocation.exclude": {
          "_ip": "10.17.67.88"
        }
      }
    }
  }
}
```



## searchguard 限制某些用户只允许查询某个特定字段值的doc

在Document Level Security Query添加条件

```sh
{
  "bool": {
    "must_not": [],
    "must": [
      {
        "terms": {
          # 只允许查询title为1的doc
          "title": ["1"]
        }
      }
    ]
  }
}
```

## indices 

```sh
GET _cat/indices?v                 # 索引状态，主分片数，副本数，doc条数，大小

GET _cat/indices?help              # 查看参数

GET _cat/indices?v&health=yellow   # 筛选索引状态

GET _cat/indices?v&s=docs.count:desc  # 索引按条数排序
# docs.count 可换 pri 分片数，rep 副本数，store.size 存储大小

GET _cat/indices?v&h=i,r,dc&s=dc:desc   # 只显示index，replica，docs.count

GET /_cat/indices?v&h=i,tm&s=tm:desc    # 查看每个索引占用内存

# 总结v显示列名，h要显示的列，s可排序，关于列的选择可看help
```



## task

```sh
GET _tasks/?pretty=true&detailed=true&actions=*search   # 任务详情 

POST _tasks/node_id:task_id/_cancel                     # 取消任务


GET _tasks
GET _tasks?nodes=nodeId1,nodeId2&actions=cluster:*

GET _tasks?actions=*search&detailed=true
GET _tasks?actions=*update&detailed=true
GET _tasks?actions=*merge&detailed=true
GET _tasks?actions=*reindex&detailed=true



POST _tasks/_cancel?nodes=nodeId1,nodeId2&actions=*reindex   # 取消多个任务

# 查看reindex任务过程
cat _tasks/?pretty&detailed=true&actions=*reindex

# 查看排队中的任务
GET /_cat/pending_tasks?v
# pending_tasks 全是 put_mappings 这类操作，特别是如果用了动态mapping的情况下，比较容易因为新字段的写入产生mapping更新任务。
# 动态 mapping 非常容易引起性能问题，特别是集群比较大的情况下，容易因为大量的 mapping 更新任务会导致master过载。 可完全禁用动态 mapping
```



# Reindex

## 远程

yml配置：
```sh
reindex.remote.whitelist: "XXX.XXX.XXX.XXX:9200"
```

获取原模板：`GET _template`，修改refresh_interval为-1，number_of_replicas为0

```sh
POST _reindex
{

  "size": 5,
  "conflicts": "proceed",

  "source": {
    "remote": {
      "host": "http://oldhost:9200",
      "username": "user",
      "password": "pass"
    },

    "size": 2,      # 每批次量
    "index": "oldIndex",
    "type": "",
    "_source": ["name"],
    "query": {
      "match": {
        "test": "data"
      }
    }
  },

  "dest": {
    "index": "newIndex",       # 新索引
    "op_type": "create",       # 操作类型创建
    "routing": "=value"        # 以什么值为路由
  }
}
```

## 集群内 reindex

适用修改、增加原有数据的类型

事先创建创建_template，并创建索引
```sh
# 数据量不大就无须此步骤
PUT */_settings
{
    "refresh_interval": "5s",   # 设置-1
    "number_of_replicas": 1     # 设置0
}
```

```sh
POST _reindex
{
  "conflicts": "proceed",
  "source": {
    "index": "oldIndex",
    "query": {
     "terms":{  
         "fields.host":["651-2201", "10.32.65.49"]
      }
    }
  },
  "dest": {
    "index": "newIndex", 
    "op_type": "create"  
  }
}

# 查看过程
cat _tasks/?pretty&detailed=true&actions=*reindex
```


## 处理 关闭的索引无法滚动而触发的告警

```sh
POST yw-dns-wh-outer-log_write/_rollover
{
  "conditions": {
    "max_age": "1000d",
    "max_docs": 2000000000,
    "max_size": "210gb"
  }
}
GET _cat/aliases?v

PUT /%3Cyw-dns-wh-outer-log-%7Bnow%2Fd%7D-000001%3E
{
  "aliases": {
    "yw-dns-wh-outer-log_write": {}
  }
}

POST _aliases
{
  "actions": [
    {"remove": {
      "index": "yw-dns-wh-outer-log-2020.04.21-000001", 
      "alias": "yw-dns-wh-outer-log_write"
    }}
  ]
}
```



# rollover 自动限制索引大小

1. 手动创建索引，以及别名
```sh
# PUT /<logs-{now/d}-1>  例如：logs-2020.05.18-000001
PUT /%3Clogs-%7Bnow%2Fd%7D-000001%3E
{
  "aliases": {
    "logs_test_write": {}
  }
}
```

2. 修改logstash写入es的logs_test_write

3. 测试一下rollover

```sh
POST logs_test_write/_rollover
{
  "conditions": {
    "max_age": "7d",
    "max_docs": 10,
    "max_size": "5g"
  }
}
```
索引按照【”-”+数字】的形式结尾，新创建的索引数字+1，数字为6位，不够前面以0补齐。


4. 每次POST才会检查，所以需要写成cron定时任务
```sh
#!/bin/sh
curl -X POST "http://xxx.xxx.xxx.xxx/logs_test_write/_rollover" -H "Content-Type:application/json" -d '{"conditions": {"max_age": "1d", "max_docs": 10, "max_size": "100g"}}' 
```



# 单节点重启


集群可能会有整体重启的需要，比如需要升级硬件、升级操作系统或者升级ES大版本。重启所有结点可能带来的一个问题: 某些结点可能先于其他结点加入集群。 先加入集群的结点可能已经可以选举好master，并立即启动了recovery的过程，由于这个时候整个集群数据还不完整，master会指示一些结点之间相互开始复制数据。 那些晚到的结点，一旦发现本地的数据已经被复制到其他结点，则直接删除掉本地“失效”的数据。 当整个集群恢复完毕后，数据分布不均衡显然是不均衡的，master会触发rebalance过程，将数据在结点之间挪动。整个过程无谓消耗了大量的网络流量。


升级版本或者故障，单个node关闭之前，关闭分片自动分配。
此时关闭节点，集群yellow。此节点primary在其他节点的replica被推荐为primary，自己变成replica。
由于设置为"none"，此节点replica不会在其他节点上复制恢复，保持unassigned状态。

重启后replica与primary存在差异时（即primary持续有新数据写入），需进入recovery过程。此过程需要主副之间拷贝数据，或者利用translog重放热数据。


一般关闭前：合并segment（refresh一次一个segment，尽可能少segment）；flush数据到磁盘；关闭自动分片。

```sh

PUT _cluster/settings
{
	"persistent": {
		"cluster.routing.allocation.enable": "none"
		# 关闭分片自动分配，"all"为开启
	}
}

POST _flush/synced   # 手动同步，segment数据刷到磁盘

PUT */_settings
{
	"refresh_interval": -1     
}
```

启动后

```sh
PUT _cluster/settings
{
	"persistent": {
		"cluster.routing.allocation.enable": "all"
	}
}

# 此时集群有大量的 unassigned 分片，集群处于 yellow 状态。为了加快集群恢复的速度
PUT _cluster/settings
{
	"persistent": {
		# 调整分片恢复并发数，默认2
        "cluster.routing.allocation.node_concurrent_recoveries": 20,
        # 默认20mb，设置"none"为磁盘极限，提升recovery速度，减少数据写入被阻塞的时长
        "indices.recovery.max_bytes_per_sec": "40mb"
    }
}

##允许在一个节点上发生多少并发传入分片恢复。 默认为2
##多数为副本
"cluster.routing.allocation.node_concurrent_incoming_recoveries":2
##允许在一个节点上发生多少并发传出分片恢复，默认为2
## 多数为主分片
"cluster.routing.allocation.node_concurrent_outgoing_recoveries":2
##为上面两个的统一简写
"cluster.routing.allocation.node_concurrent_recoveries":2
```



