---
layout: post
title: "ES 常用操作"
date: 2020-05-31
description: "Elasticsearch"
tag: ELK

---


## jvm.options 换 GC
```sh
-XX:+UseG1GC
-XX:MaxGCPauseMillis=200
```

## 临时修改es打印日志等级
```sh
PUT _cluster/settings
{
  "transient":{ 
    "logger.org.elasticsearch.index": "trace"
  }
}
```


## 修改索引，副本数量，refresh时间
```sh
# 数据量不大就无须此步骤
PUT index_name/_settings
{
    "refresh_interval": "5s",  
    "number_of_shards": 2,        # 分片数不能动态修改
    "number_of_replicas": 1

}
```

## 部分主分片未分配，集群显示red
```sh
GET _cluster/allocation/explain    # 查看主分片未分配原因 

GET _cat/indices?v                 # 查看哪些索引red
# 不重要索引，可直接close

GET _cat/shards?v                  # 查看每个分片分布节点

# shard 自动分配最大次数 5 次，即使发现集群通信正常后也不会自动子再分配
POST _cluster/reroute?retry_failed=true  # 让达到限制次数的未分配的分片再次进行分配
# index.allocation.max_retries 参数来控制最大重试次数
```

## 查看各个分片分别在哪些节点上
```sh
GET _cat/shards?v

GET _cat/allocation?v   # 查看每个节点的磁盘占用

GET _cat/fielddata?v&s=size:desc    # 可以查看字段占用的堆内存
```


## 合并segment
```sh
GET _cat/segments/索引名?v                  # segment大小（默认5G），内存
POST 索引名/_forcemerge?max_num_segments=1  # 合并成一个（根据具体情况）
GET _tasks?actions=*merge&detailed=true        
```


## 修改索引字段数量
```sh
PUT index_name/_settings
{
  "index.mapping.total_fields.limit": 3000  # 默认最多字段数1000
}
```


## 关闭索引
```sh
POST 索引名/_close
POST 索引名/_open
# 索引关闭，开销基本0，但无法进行读写
```


## 删除.del文件
```sh
# es在检索过程中也会把.del文件进行检索过滤，如有大量的.del文件，应该让.del真正的从es中抹去，优化检索的效率。
# 在索引合并阶段就会删除.del文件
curl -X POST "http://node01:9200/索引名/_forcemerge?only_expunge_deletes=true"
```


## 查询特殊符号命名的index
转义字符用：%
例如：
```sh
# GET /<logstash-{now/d}>/_search
GET /%3Clogstash-%7Bnow%2Fd%7D%3E/_search
```


## 修改searchguard副本数

```sh
PUT searchguard/_settings
{
  "index": {
    "auto_expand_replicas": "0-3"
  }
}
```

## 防止脑裂导致版本差异

```sh
PUT _cluster/settings
{
  "transient": {
    "discovery": {
      "zen": {         # 一般3个master即可
        "minimun_master_nodes": "2"
      }
    }
  }
}
```

## 文档刷新时间

```sh
PUT */_settings
{
  "refresh_interval": -1
}
```


## Kibana 查询中文索引
链接中的中文需要URL编码，而DSL里面直接中文即可
```sh
PUT /%3Cdylog-%e6%b5%8b%e8%af%95-%7Bnow%2Fd%7D-000001%3E
{
  "aliases": {
    "dylog-测试_write": {}
  }
}
``` 


## 禁止通配符 * 删除索引
```sh
PUT /_cluster/settings
{
  "persistent": {
    "action.destructive_requires_name": "true"
  }
}
```


## 将节点所有分片移走
```sh
PUT _cluster/settings
{
  "transient": {
    "cluster": {
      "routing": {
        "allocation.exclude": {
          "_ip": "10.17.67.88"
        }
      }
    }
  }
}
```


## 手动将某节点上的index移动到另一个节点
```sh
POST _cluster/reroute
{
  "commands": [
    {
      "move": {
        "index": "test_index",
        "share": 8,
        "from_node": "es-data-node-01",
        "to_node": "es-data-node-02"
      }
    }
  ]
}
```


## searchguard 限制某些用户只允许查询某个特定字段值的doc
在Document Level Security Query添加条件
```sh
{
  "bool": {
    "must_not": [],
    "must": [
      {
        "terms": {
          # 只允许查询title为1的doc
          "title": ["1"]
        }
      }
    ]
  }
}
```

## indices 以及参数介绍
```sh
GET _cat/indices?v                 # 索引状态，主分片数，副本数，doc条数，大小

GET _cat/indices?help              # 查看参数

GET _cat/indices?v&health=yellow   # 筛选索引状态

GET _cat/indices?v&s=docs.count:desc  # 索引按条数排序
# docs.count 可换 pri 分片数，rep 副本数，store.size 存储大小

GET _cat/indices?v&h=i,r,dc&s=dc:desc   # 只显示index，replica，docs.count

GET /_cat/indices?v&h=i,tm&s=tm:desc    # 查看每个索引占用内存

# 总结v显示列名，h要显示的列，s可排序，关于列的选择可看help
```



## task

```sh
GET _tasks/?pretty=true&detailed=true&actions=*search   # 任务详情 

POST _tasks/node_id:task_id/_cancel                     # 取消任务


GET _tasks
GET _tasks?nodes=nodeId1,nodeId2&actions=cluster:*

GET _tasks?actions=*search&detailed=true
GET _tasks?actions=*update&detailed=true
GET _tasks?actions=*merge&detailed=true
GET _tasks?actions=*reindex&detailed=true

POST _tasks/_cancel?nodes=nodeId1,nodeId2&actions=*reindex   # 取消多个任务

# 查看reindex任务过程
cat _tasks/?pretty&detailed=true&actions=*reindex

# 查看排队中的任务
GET /_cat/pending_tasks?v
# pending_tasks 全是 put_mappings 这类操作，特别是如果用了动态mapping的情况下，比较容易因为新字段的写入产生mapping更新任务。
# 动态 mapping 非常容易引起性能问题，特别是集群比较大的情况下，容易因为大量的 mapping 更新任务会导致master过载。 可完全禁用动态 mapping

GET _cat/thread_pool?v  # 查看线程池
```

## nodes

```sh
# 各节点信息
GET _nodes

GET _nodes/<node_id>   # 某个节点信息

GET _nodes/settings    # 所以节点某项信息

GET _nodes/hot_threads
```



# 分析 CPU 高原因以及繁忙线程

```sh
#查看hot_threads。
GET _nodes/hot_threads
```

```sh
# 获取 pid 的所有线程 cpu 使用情况
top -H -b -n 1 -p $pid  
# -p 查看进程详情
# -H 线程
# -b 以批处理模式启动top命令
# -n 设置迭代数量

# 查看 pid 所有线程堆栈
jstack $pid
```



# Reindex

## 最简单直接转数据
```sh
POST _reindex
{
  "source": {
    "index": "oldIndex"
  },
  "dest": {
    "index": "newIndex"
  }
}
```

## 远程

新集群 kibana 直连的 ES 的 yml 配置：
```sh
reindex.remote.whitelist: "XXX.XXX.XXX.XXX:9200"
```

获取原模板：`GET _template`，修改refresh_interval为-1，number_of_replicas为0

```sh

# 在新集群的kibana执行
POST _reindex
{

  "size": 5000,                   # reindex 总条数
  "conflicts": "proceed",         # 发生冲突也继续进行 reindex

  "source": {
    "remote": {
      "host": "http://oldhost:9200",   # 旧集群的数据节点地址，同时记得开启此地址的防火墙
      "username": "user",
      "password": "pass",
      "socket_timeout": "1m",
      "connect_timeout": "10s"
    },
    "size": 1000,                  # 每批次量，scroll batches 默认 1000
    "index": "oldIndex",
    "type": "",                    # 指定哪种type进行reindex，6.0版本后index只能允许一个type
    "_source": ["name"],
    "query": {
      "match": {
        "test": "data"
      }
    }
  },

  "dest": {
    "index": "newIndex",       # 新索引
    "op_type": "create",       # 操作类型创建
    "routing": "value",        # 以什么值为路由
    "type": "doc"              # reindex 进来的数据 type 全部设为 doc
  },


  ## 利用 script 修改 oldIndex 某个字段的名字，到 newIndex 里。
  "script": {
    "source": "ctx._source.tag = ctx._source.remove(\"flag\")"
  }
}


# 可随时取消 reindex 任务
GET _tasks/?pretty&detailed=true&actions=*reindex

POST _tasks/7EgqykHmRKuMhsDQmmktSQ:15828/_cancel  
```

## 集群内 reindex

适用修改、增加原有数据的类型

```sh
GET _cat/aliases

# 1. logs-2020.05.18-000001   此时应该有两个logs_write别名的索引，数据写入不成功
# 此时新索引应该是新的mapping
PUT /%3Clogs-%7Bnow%2Fd%7D-000001%3E
{
  "aliases": {
    "logs_write": {}
  }
}

# 2. 去掉老索引的别名，再将老索引数据reindex新索引即可
POST _aliases
{
  "actions": [
    {"remove": {                           # 增加 add
      "index": "logs-2020.05.02-000001",
      "alias": "yw-dns-wh-outer-log_write"
    }}
  ]
}
```

事先创建创建_template，并创建索引
```sh
# 数据量不大就无须此步骤
PUT */_settings
{
    "refresh_interval": "5s",   # 设置-1
    "number_of_replicas": 1     # 设置0
}
```

```sh
POST _reindex
{
  "conflicts": "proceed",
  "source": {
    "index": "oldIndex",
    "query": {
     "terms":{  
         "fields.host":["651-2201", "10.32.65.49"]
      }
    }
  },
  "dest": {
    "index": "newIndex", 
    "op_type": "create"  
  }
}

# 查看过程
GET _tasks/?pretty&detailed=true&actions=*reindex
```


## 处理 关闭的索引无法滚动而触发的告警

```sh
POST yw-dns-wh-outer-log_write/_rollover
{
  "conditions": {
    "max_age": "1000d",
    "max_docs": 2000000000,  # 索引上限21亿条，经测试是一个分片，如果一个索引3分片，则会写到63亿doc
    "max_size": "210gb"
  }
}
GET _cat/aliases?v

PUT /%3Cyw-log-%7Bnow%2Fd%7D-000001%3E
{
  "aliases": {
    "yw-log_write": {}
  }
}

POST _aliases
{
  "actions": [
    {"remove": {
      "index": "yw-dns-wh-outer-log-2020.04.21-000001", 
      "alias": "yw-dns-wh-outer-log_write"
    }}
  ]
}
```



# rollover 自动限制索引大小

1. 手动创建索引，以及别名
```sh
# PUT /<logs-{now/d}-1>  例如：logs-2020.05.18-000001
PUT /%3Clogs-%7Bnow%2Fd%7D-000001%3E
{
  "aliases": {
    "logs_write": {}
  }
}
```

2. 修改logstash写入es的logs_test_write

3. 测试一下rollover

```sh
POST logs_test_write/_rollover
{
  "conditions": {
    "max_age": "7d",
    "max_docs": 10,
    "max_size": "5g"
  }
}
```
索引按照【”-”+数字】的形式结尾，新创建的索引数字+1，数字为6位，不够前面以0补齐。


4. 每次POST才会检查，所以需要写成cron定时任务
```sh
#!/bin/sh
curl -X POST "http://xxx.xxx.xxx.xxx/logs_test_write/_rollover" -H "Content-Type:application/json" -d '{"conditions": {"max_age": "1d", "max_docs": 10, "max_size": "100g"}}' 
```


## 别名问题
```sh
# PUT /<logs-{now/d}-1>  例如：logs-2020.05.18-000001
PUT /%3Clogs-%7Bnow%2Fd%7D-000001%3E
{
  "aliases": {
    "logs_write": {}
  }
}
```

关于时间：
- {now}   默认按照天 {now/d}
- {now/d} 2020-05-22-000001，滚动切割后，数字+1，非同一天 day 变成当前日期
- {now/M} 2020-05-01-000001，滚动切割后，数字+1，非同一月 month 变成当前月份 （day:01）
- {now/y} 2020-01-01-000001，滚动切割后，数字+1，非同一年 year 变成当前年份  （month:01, day:01）

用 nginx 做域名代理，将索引名URL编码再发送，http://test.com/data/%3Clogs-%7Bnow%2Fd%7D-000001%3E ，
发现 nginx 不能接受到 {now/d} 的反斜杠，提示405 method not allowed。而不用域名直接发送到某个节点9200是可以的。
解决是直接使用 {now}。



# 单节点重启


集群可能会有整体重启的需要，比如需要升级硬件、升级操作系统或者升级ES大版本。重启所有结点可能带来的一个问题: 某些结点可能先于其他结点加入集群。 先加入集群的结点可能已经可以选举好master，并立即启动了recovery的过程，由于这个时候整个集群数据还不完整，master会指示一些结点之间相互开始复制数据。 那些晚到的结点，一旦发现本地的数据已经被复制到其他结点，则直接删除掉本地“失效”的数据。 当整个集群恢复完毕后，数据分布不均衡显然是不均衡的，master会触发rebalance过程，将数据在结点之间挪动。整个过程无谓消耗了大量的网络流量。


升级版本或者故障，单个node关闭之前，关闭分片自动分配。
此时关闭节点，集群yellow。此节点primary在其他节点的replica被推荐为primary，自己变成replica。
由于设置为"none"，此节点replica不会在其他节点上复制恢复，保持unassigned状态。

重启后replica与primary存在差异时（即primary持续有新数据写入），需进入recovery过程。此过程需要主副之间拷贝数据，或者利用translog重放热数据。


一般关闭前：合并segment（refresh一次一个segment，尽可能少segment）；flush数据到磁盘；关闭自动分片。

```sh

PUT _cluster/settings
{
	"persistent": {     # transient 为临时，优先使用。所以暂时停止分片应该使用 transient
		"cluster.routing.allocation.enable": "none"
		# 关闭分片自动分配，"all"为开启
	}
}

    */_refresh
POST _flush/synced   # 手动同步，segment数据刷到磁盘

PUT */_settings
{
	"refresh_interval": -1     
}
```

启动后

```sh
PUT _cluster/settings
{
	"persistent": {
		"cluster.routing.allocation.enable": "all"
	}
}

# 此时集群有大量的 unassigned 分片，集群处于 yellow 状态。为了加快集群恢复的速度
PUT _cluster/settings
{
	"persistent": {
		# 调整分片恢复并发数，默认2
        "cluster.routing.allocation.node_concurrent_recoveries": 20,
        # 默认20mb，设置"none"为磁盘极限，提升recovery速度，减少数据写入被阻塞的时长
        "indices.recovery.max_bytes_per_sec": "40mb"
    }
}

##允许在一个节点上发生多少并发传入分片恢复。 默认为2
##多数为副本
"cluster.routing.allocation.node_concurrent_incoming_recoveries":2
##允许在一个节点上发生多少并发传出分片恢复，默认为2
## 多数为主分片
"cluster.routing.allocation.node_concurrent_outgoing_recoveries":2
##为上面两个的统一简写
"cluster.routing.allocation.node_concurrent_recoveries":2
```


# 重启数据节点实际案例

更配置重启 data 节点


cluster 临时修改：
```sh
PUT _cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "none"
  }
}
POST */_refresh      # 
POST _flush/synced   # 手动同步，segment数据刷到磁盘
```

下线 data 节点，更新后重启

重新上线后，恢复分片
```sh
PUT _cluster/settings
{
  "transient": {
    "cluster.routing.allocation.enable": "all"
  }
}
```

最后等到 green 后再进行下一个 data 节点下线。


## 问题

情景：当时急于快速更新多个 data节点，没等 cluster 恢复 green，立即下线新 的 data 节点，虽然一分钟内又重启，还是 red 状态。


问题：

1. data 节点数据丢失，多个索引 red 

2. .kibana 索引 red，导致 kibana 无法启动连接

3. 集群无法写入数据，同一个 logstash 消费 kafka 写多个集群，导致另外两个集群也无法写入数据

解决：

```sh
POST _cluster/reroute?retry_failed=true    # 进行再分配，等待集群恢复

# 查看相关分片情况
GET _cat/shards?v

GET _cluster/allocation/explain
```

等到索引恢复 green 后，集群又恢复写数据，因为索引 red 状态无法确定主分片，无法消费 kafka 写入 ES




# 修复主分片 

```sh
GET _cat/indices?v&health=red          #  查看 red 状态索引

GET _cluster/allocation/explain        # 查看当前 shard 未分配原因

GET _cluster/allocation/explain        # 可以指定某个索引的某个 shard 未分配原因 
{
  "index": "test-index",
  "shard": 2,
  "primary": true
}

POST _cluster/reroute?retry_failed=true

GET _cat/shards?v&index=test-index*   # 查明具体哪个 shard 未分配
```


## 修复
```sh
## 在 explain 的节点找到含有 allocation_id 的节点
"store": {
  "in_sync": false,
  "allocation_id": "KTBfSjhZQMWnX84QaC3Hmg"
}

## 修复
POST _cluster/reroute?pretty
{
  "commands": [
    {
      "allocate_stable_primary": {
        "index": "test-index",
        "shard": 2,
        "node": "data01",    # 必须有 allocation_id
        "accept_data_loss": true
      }
    }
  ]
}


## 如果在没有 allocation_id 的节点修复，发现shard还是未分配状态
"store": {
  "in_sync": true,
  "allocation_id": "krhB9UpMQrirKL4W-UOI8A",
  "store_exception": {
    "type": "file_not_found_exception",
    "reason": "no segments* file found in SimpleFSDirectory@/data/datanode_4/nodes/0/indices/XUT6I8ezQ0i6qE1CpW9AmA/1/index lockFactory=org.apache.lucene.store.NativeFSLockFactory@2b0c2cf8: files: []"
  }
}
```

```sh
## 如果所有节点都没有 allocation_id，则只能将此 shard 置空，即 shard 数据全部丢失
POST _cluster/reroute?pretty
{
  "commands": [
    {
      "allocate_empty_primary": {
        "index": "test-index",
        "shard": 2,
        "node": "data01",
        "accept_data_loss": true
      }
    }
  ]
}
```

- allocate_stale_primary 用于将一个陈旧的分片分配为主分片。使用此命令意味着丢失给定分片副本中缺少的数据。

- allocate_empty_primary 强制Elasticsearch使用空分片副本分配主分片，这意味着丢失与该分片相关联的所有先前数据。
