---
layout: post
title: "Google语言模型bert进行简单分类"
date: 2018-10-08
description: "简单介绍一下如何使用bert进行文本分类"
tag: NLP

---

# 使用介绍

模型下载地址：[bert模型](https://github.com/google-research/bert)

修改run_classifier.py文件，并自定义分类器

```python
import pandas as pd
class SimProcessor(DataProcessor):
  def get_train_examples(self, data_dir):
    file_path = os.path.join(data_dir, 'train.csv')    # 路径拼接
    train_df = pd.read_csv(file_path, encoding='GBK')
    train_data = []
    for index, train in enumerate(train_df.values):    # 遍历数据
      guid = 'train-%d' % index
      test_a = tokenization.convert_to_unicode(str(train[0]))
      label = str(train[1])
      train_data.append(InputExample(
          guid=guid, text_a=test_a, text_b=None, label=label))
    return train_data

  def get_test_examples(self, data_dir):
    file_path = os.path.join(data_dir, 'test.csv')
    test_df = pd.read_csv(file_path, encoding='GBK')
    test_data = []
    for index, test in enumerate(test_df.values):
      guid = 'test-%d' % index
      test_a = tokenization.convert_to_unicode(str(test[0]))
      label = str(test[1])
      test_data.append(InputExample(
          guid=guid, text_a=test_a, text_b=None, label=label))
    return test_data

  def get_dev_examples(self, data_dir):
    file_path = os.path.join(data_dir, 'dev.csv')
    dev_df = pd.read_csv(file_path, encoding='GBK')
    dev_data = []
    for index, dev in enumerate(dev_df.values):
      guid = 'dev-%d' % index
      test_a = tokenization.convert_to_unicode(str(dev[0]))
      label = str(dev[1])
      dev_data.append(InputExample(
          guid=guid, text_a=test_a, text_b=None, label=label))
    return dev_data

  def get_labels(self):
    return ['0', '1']

```

添加自定义分类器

```python
def main():
	tf.logging.set_verbosity(tf.logging.INFO)
	processors = {
		"sim" : SimProcessor
	}

```

将数据文件夹、中文模型chinese_L-12_H-768_A-12文件夹、bert-master同一目录

执行命令：
```
export BERT_BASE_DIR=../chinese_L-12_H-768_A-12
export MY_DATASET=../split_cut 
python3 run_classifier.py \
  --data_dir=$MY_DATASET \
  --task_name=sim \
  --vocab_file=$BERT_BASE_DIR/vocab.txt \
  --bert_config_file=$BERT_BASE_DIR/bert_config.json \
  --output_dir=./tmp/sim_model/ \
  --do_train=true \
  --do_eval=true \
  --init_checkpoint=$BERT_BASE_DIR/bert_model.ckpt \
  --max_seq_length=128 \
  --train_batch_size=32 \
  --learning_rate=5e-5\
  --num_train_epochs=2.0
```

预测：
```
python3 run_classifier.py \
  --task_name=sim \
  --do_predict=true \
  --data_dir=$MY_DATASET \
  --vocab_file=$BERT_BASE_DIR/vocab.txt \
  --bert_config_file=$BERT_BASE_DIR/bert_config.json \
  --init_checkpoint=./tmp/sim_model \
  --max_seq_length=128 \
  --output_dir=./tmp/output/
```
在data_dir下有测试数据，测试完成后会在output_dir路径下生成一个test_results.tsv文件，
该文件包含了测试用例和相似度probabilities

# 参考

https://www.jiqizhixin.com/articles/2019-02-18-12?from=synced&keyword=bert

https://github.com/google-research/bert

