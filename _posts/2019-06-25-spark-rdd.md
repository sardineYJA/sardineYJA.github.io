---
layout: post
title: "RDD函数"
date: 2019-06-25
description: "介绍一下Spark Core的RDD函数"
tag: 大数据

---

# 简介

以后补充

## Transformation

```java
1. map(func)
sc.parallelize(1 to 3).map(_*2)
// Array(2, 4, 6)

2. filter(func)
sc.parallelize(Array("123", "345", "567")).filter(_.contains("3"))
// Array(123, 345)

3. flatMap(func)
sc.parallelize(1 to 3).flatMap(1 to _)
// flatMap Array(1, 1,2, 1,2,3)

4. mapPartitions(func)   // 分区

5. mapPartitionsWithIndex(func)

6. sample(withReplacement, fraction, seed) // 随机抽取

7. takeSample     // 这个是action操作

8. union(otherDataset)   // 求并集
sc.parallelize(1 to 3).union(sc.parallelize(3 to 5))
// Array(1,2,3, 3,4,5)

9. intersection(otherDataset)  // 求交集

10. distinct([numTasks])      // 去重
sc.parallelize(List(1,1,2,2)).distinct(2)
// Array(1,2)

11. partitionBy     // 进行分区
sc.parallelize(Array((1,"a"), (2,"b"), (3,"c"))).partitionBy(HashPartitioner(2))

12. reduceByKey(func, [numTasks])   // 相同key的value进行func

13. groupByKey

14. combineByKey[C]

15. aggregateByKey

16. foldByKey

17. sortByKey([ascending], [numTasks])    // 排序，truc升序
sc.parallelize(Array((2,"b"), (1,"a"), (3, "c"))).sortByKey(true).sortByKey(false)

18. sortBy(func, [ascending], [numTasks])  // 先进行func后再排序

19. join(otherDataset, [numTasks])   // (K,V)和(K,W) => (K,(V,W))

20. cogroup(otherDataset, [numTasks])

21. cartesian(otherDataset)   // 笛卡尔积

22. pipe(command, [envVars])  // 执行脚本

23. coalesce(numPartitions)   // 缩减分区数

24. repartition(numPartitions) // 根据分区数重洗数据

25. repartitionAndSortWithinPartitions(partitioner)

26. glom   // 将每个分区形成一个数组
sc.parallelize(1 to 16, 4).glom().collect()
// Array(Array(1,2,3,4), Array(5,6,7,8), Array(9,10,11,12), Array(13,14,15,16))

27. mapValues  // 只对V操作
sc.parallelize(Array((1,"a"), (2,"b"))).mapValues(_+"T")
// Array((1,aT), (2,bT))

28. subtract  // 计算差集
sc.parallelize(3 to 5).subtract(sc.parallelize(1 to 3))
// Array(4, 5)
```

## Action

```java
1. reduce(func)

2. collect()

3. count() 

4. first()

5. take(n)   // 取出前n个元素
sc.makeRDD(1 to 10, 2).take(5)
// Array(1,2,3,4,5)

6. takeSample(withReplacement, num, [seed]) 
sc.parallelize(1 to 10).takeSample(true, 5, 3)  // 有放回抽取5个

7. takeOrder(n)   // 升序排序返回前n个

8. top(n)         // 降序排序返回前n个

9. aggregate

10. fold(num)(func)

11. saveAsTextFile(path)      // 保存

12. saveAsSequenceFile(path)  // 以Hadoop sequencefile格式保存

13. saveAsObjectFile(path)    // 序列化成对象

14. countByKey()    // 计算K的个数

15. foreach(func)   // 每个元素进行func更新
```

```java
// 数值RDD的统计操作
1. count()
2. mean()
3. sum()
4. max()
5. min()
6. variance()        // 方差
7. sampleVariance()  // 采样集的方差
8. stdev()           // 标准差
9. sampleStdev()     // 采样集的方差
```


